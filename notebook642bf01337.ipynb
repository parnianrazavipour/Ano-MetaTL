{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2","metadata":{"id":"sdUYq0D6TdvE","execution":{"iopub.status.busy":"2023-02-09T12:51:36.852095Z","iopub.execute_input":"2023-02-09T12:51:36.852572Z","iopub.status.idle":"2023-02-09T12:51:36.893154Z","shell.execute_reply.started":"2023-02-09T12:51:36.852475Z","shell.execute_reply":"2023-02-09T12:51:36.892290Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install learn2learn","metadata":{"id":"6npi8bGt2IyS","outputId":"c4d440cc-67bb-4038-aefe-b398763c6288","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/parnianrazavipour/Ano-MetaTL.git\n%cd Ano-MetaTL\n!git checkout origin/ad_maml","metadata":{"id":"6qYS9wSEsEwr","outputId":"5ce3a9e2-d089-4eaa-c631-34eb77890511","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drive.mount('/content/drive')\n","metadata":{"id":"YZItj6PHrlhZ","outputId":"28754d31-6af6-4650-fbc4-9f995a1c7ea5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os\n# path = \"../drive/MyDrive/Rabiee/Social/metatl_beauty/models\"\n# os.system(f'cp -r {path} .')\n# path = \"../drive/MyDrive/Rabiee/Social/data/\"\n# os.system(f'cp -r {path} .')\n","metadata":{"id":"c4DVKQ4BryGG","outputId":"f8a55134-21ae-4ee7-ea45-bbc5d195e054"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import os \nimport pandas as pd\nimport numpy as np\n\nk = 5\nmin_intrac = k+1 \n#set w.r.t k\ntrain_test_p = 0.7\n\nratings = pd.read_csv(\"/kaggle/input/ratings-beauty/ratings_Beauty.csv\",\n                      names=['user_id', 'product_id','rating','timestamp'])\n\nratings = ratings[ratings.groupby('user_id')['user_id'].transform('count').ge(min_intrac)]\n\nstart_df = ratings.groupby(['user_id'])['timestamp'].agg('min')\nratings['start_ts'] = ratings['user_id'].apply(lambda x: start_df[x])\nratings = ratings.sort_values(['start_ts', 'user_id', 'timestamp'], ascending=[True, True, True])\n\nall_user, idx = np.unique(ratings['user_id'], return_index=True)\nuser_dic = {}\nall_user = all_user[np.argsort(idx)]\nfor i, user in enumerate(all_user):\n    user_dic[user] = i + 1\nratings['user_id'] =  ratings['user_id'].apply(lambda user: user_dic[user])\n\nall_item, item_idx = np.unique(ratings['product_id'], return_index=True)\nitem_dic = {}\nall_item = all_item[np.argsort(item_idx)]\nfor i, item in enumerate(all_item):\n    item_dic[item] = i + 1\nratings['product_id'] =  ratings['product_id'].apply(lambda item: item_dic[item])\n\nratings = ratings.reset_index(drop=True)\nratings = ratings.drop(['rating', 'start_ts'], axis=1)\n\nsep_user = max(ratings.user_id) * (train_test_p)\ntrain_df = ratings[ratings['user_id'] <= sep_user]\ntest_df = ratings[ratings['user_id'] > sep_user]\ntest_df = test_df[test_df.product_id <= max(train_df.product_id)]\n\nif not os.path.exists('./data'):\n    os.mkdir('./data')\nif not os.path.exists('./data/beauty'):\n    os.mkdir('./data/beauty')\n    \ntrain_df.to_csv('data/beauty/beauty_train.csv', sep='\\t', header=False, index=False)\ntest_df.to_csv('data/beauty/beauty_test_new_user.csv', sep='\\t', header=False, index=False)","metadata":{"id":"nArZhXjA7dkD","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd Ano-MetaTL\n%pwd\n# !conda install pytorch --yes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch, random\nimport os \n\nclass Arguments:\n    def __init__(self):\n        self.dataset = \"beauty\"\n        self.seed = 0\n        self.K = 5\n        self.embed_dim = 100\n        self.batch_size = 1024\n        self.learning_rate = 0.001\n        self.epoch = 20000\n        self.print_epoch = 100\n        self.eval_epoch = 500\n        self.beta = 5\n        self.margin = 1\n        self.dropout_p = 0.5\n        self.device = 0\n        self.ano_k = self.K\n        self.adapt_lr = 0.01\n        self.meta_lr = 0.005\n        self.metatl_path = 'models/metatl.pt'\n        self.ad_maml_path = 'models/maml_ad.pt'\n\nargs = Arguments()\nargs.device = torch.device('cuda:'+str(args.device))\nparams = {}\nfor attr, value in args.__dict__.items():\n    params[attr] = value\n# params['device'] = torch.device('cuda:'+str(args.device))\n# args.device = 'cpu'\n# params['device'] = 'cpu'","metadata":{"id":"1ybwiY8U1hSC","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from trainer import *\nfrom utils import *\nfrom sampler import *\nimport json\n\n\nif params['seed'] is not None:\n    SEED = params['seed']\n    torch.manual_seed(SEED)\n    torch.cuda.manual_seed(SEED)\n    torch.backends.cudnn.deterministic = True\n    np.random.seed(SEED)\n    random.seed(SEED)\n\nuser_train, usernum_train, itemnum, user_input_test, user_test, user_input_valid, user_valid = data_load(args.dataset, args.K)    \n\ntrain_dataset = WarpSampler(user_train, usernum_train, itemnum, sample_function_mixed, batch_size=args.batch_size, maxlen=args.K, n_workers=3)\n\ntest_dataset = DataLoader(user_input_test, user_test, itemnum, params)\n\nval_dataset = DataLoader(user_input_valid, user_valid, itemnum, params)\n\n\nuser_train, usernum_train, itemnum, user_input_test, user_test, user_input_valid, user_valid = data_load(args.dataset, args.K)    \n\ntrainer = Trainer([train_dataset, val_dataset ,test_dataset], itemnum, params)\n\ntrainer.train()\n","metadata":{"id":"QqnBedVW_k_H","outputId":"f0752044-463c-4edb-996f-e25420bd6df1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%pwd\n","metadata":{"id":"uaOKyOisHHmA","outputId":"e2ddd8df-af98-45d4-cd87-77356cf419cf","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# New Section","metadata":{"id":"QFNsZET96LVG"}},{"cell_type":"code","source":"# from torch import nn\n# from models import Embedding, MetaLearner\n# from ad_maml.model import AnomalyDetector\n# from torch.autograd import grad\n# from torch import optim\n# import learn2learn as l2l\n# from collections import OrderedDict\n\n\n# class AnoMetaTL(nn.Module):\n#     def __init__(self, max_item, ad_maml, args):\n#         super(AnoMetaTL, self).__init__()\n#         self.device = args.device\n#         self.beta = args.beta\n#         self.embedding = nn.Embedding(max_item + 1, args.embed_dim)\n#         nn.init.xavier_uniform_(self.embedding.weight)\n#         self.relation_learner = MetaLearner(args.K - 1, embed_size=args.embed_dim, num_hidden1=500,\n#                                                     num_hidden2=200, out_size=100, dropout_p=args.dropout_p)\n#         self.loss_func = nn.MarginRankingLoss(args.margin)\n#         self.ad_maml = ad_maml\n\n#     def split_concat(self, positive, negative):\n#         pos_neg_e1 = torch.cat([positive[:, :, 0, :],\n#                                 negative[:, :, 0, :]], 1).unsqueeze(2)\n#         pos_neg_e2 = torch.cat([positive[:, :, 1, :],\n#                                 negative[:, :, 1, :]], 1).unsqueeze(2)\n#         return pos_neg_e1, pos_neg_e2\n\n#     def embedding_triples(self, triples):\n#         idx = [[[t[0], t[2]] for t in batch] for batch in triples]\n#         idx = torch.LongTensor(idx).to(self.device)\n#         return self.embedding(idx)\n\n#     def calculate_p_n_score(self, start, target, transition, k):\n#         score = -torch.norm(start + transition - target, 2, -1).squeeze(2)\n#         p_score = score[:, :k]\n#         n_score = score[:, k:]\n#         return p_score, n_score\n    \n#     def get_ano_support_task(self, task):\n#         support_triples, support_negative_triples, \\\n#             query_triples, negative_triples, = [item[0] for item in task]\n#         support = [*np.array(support_triples)[:, 0], np.array(support_triples)[-1, -1]]\n#         support_neg = [*np.array(support_negative_triples)[:, 2]]\n#         return support, support_neg\n\n#     def get_ano_query_task(self, task):\n#         support_triples, support_negative_triples, \\\n#             query_triples, negative_triples, = [item[0] for item in task]\n#         support = [*np.array(support_triples)[:, 0], np.array(support_triples)[-1, -1]]\n#         query = []\n#         query.append([*support[-self.ad_maml.k + 1:], query_triples[0][2]])\n#         for neg_triple in negative_triples:\n#             query.append([*support[-self.ad_maml.k + 1:], neg_triple[2]])\n#         return query\n\n#     def get_ano_preds(self, ad_maml_clone, data):\n#         data_embed = self.embedding(data)\n#         data_ano = data_embed[-1].unsqueeze(0)\n#         data_embed = data_embed.reshape(-1).unsqueeze(0)\n#         preds = ad_maml_clone(data_embed, data_ano)\n#         return preds.squeeze(0)\n\n#     def ano_support_forward(self, ad_maml_clone, task):\n#         ano_k = ad_maml_clone.k\n#         support_y = []\n#         support_neg_y = []\n#         all_support, all_support_neg = self.get_ano_support_task(task)\n#         for i, neg in enumerate(all_support_neg[:ano_k - 2]):\n#             support = all_support[:ano_k]\n#             support[-1], support[i + 1] = support[i + 1], support[-1]\n#             support = torch.tensor(support).to(self.device)\n#             support_y.append(self.get_ano_preds(ad_maml_clone, support))\n#             support_neg = [*support[:-1], neg]\n#             support_neg = torch.tensor(support_neg).to(self.device)\n#             support_neg_y.append(self.get_ano_preds(ad_maml_clone, support_neg))\n#         for i, neg in enumerate(all_support_neg[ano_k - 2:]):\n#             support = all_support[i: i + ano_k]\n#             support = torch.tensor(support).to(self.device)\n#             support_y.append(self.get_ano_preds(ad_maml_clone, support))\n#             support_neg = [*support[:-1], neg]\n#             support_neg = torch.tensor(support_neg).to(self.device)\n#             support_neg_y.append(self.get_ano_preds(ad_maml_clone, support_neg))\n#         support_y = torch.cat(support_y)\n#         support_neg_y = torch.cat(support_neg_y)\n#         return support_y, support_neg_y\n\n#     def ano_query_forward(self, ad_maml_clone, task):\n#         query_y = []\n#         all_query = self.get_ano_query_task(task)\n#         all_query = torch.tensor(all_query).to(self.device)\n#         data_embed = self.embedding(all_query)\n#         data_ano = data_embed[:, -1, :]\n#         data_embed = data_embed.reshape(data_embed.shape[0], -1)\n#         preds = ad_maml_clone(data_embed, data_ano)\n#         return preds.reshape(-1)\n\n#     # def load_model(self, metatl_path, ad_maml_path):\n#     #     #load embedder\n#     #     metatl_data = torch.load(metatl_path, map_location=torch.device(self.device))\n#     #     self.embedding.load_state_dict(OrderedDict([('weight', metatl_data['embedding.embedding.weight'])]))\n#     #     #load relation learner\n#     #     rl_name = 'relation_learner'\n#     #     all_keys = []\n#     #     for key in metatl_data.keys():\n#     #         if  rl_name in key:\n#     #             all_keys.append(key)\n\n#     #     rl_data = []\n#     #     for key in all_keys:\n#     #         rl_data.append((key[len(rl_name) + 1:], metatl_data[key]))\n#     #     self.relation_learner.load_state_dict(OrderedDict(rl_data))\n#     #     #load ad_maml\n#     #     ad_maml_data = torch.load(ad_maml_path, map_location=torch.device(self.device))\n#     #     self.ad_maml.load_state_dict(ad_maml_data)\n\n#     def forward(self, task, is_eval=False):\n#         # transfer task string into embedding\n#         support, support_negative, query, negative = [self.embedding_triples(t) for t in task]\n \n#         K = support.shape[1]              # num of K\n#         num_sn = support_negative.shape[1]  # num of support negative\n#         num_q = query.shape[1]              # num of query\n#         num_n = negative.shape[1]           # num of query negative\n\n#         rel = self.relation_learner(support)\n#         rel.retain_grad()\n#         rel_s = rel.expand(-1, K+num_sn, -1, -1)\n\n#         sup_neg_e1, sup_neg_e2 = self.split_concat(support, support_negative)\n#         p_score, n_score = self.calculate_p_n_score(sup_neg_e1, sup_neg_e2, rel_s, K)\n#         ad_maml_clone = self.ad_maml.clone()\n#         support_y, support_neg_y = self.ano_support_forward(ad_maml_clone, task)\n#         p_score = support_y * p_score\n#         n_score = support_neg_y * n_score\n\n#         y = torch.ones_like(p_score).to(self.device)\n#         support_loss = self.loss_func(p_score, n_score, y)\n#         ad_maml_clone.adapt(support_loss)\n#         rel_q = rel - self.beta * grad(support_loss, rel, retain_graph=True)[0]\n        \n#         rel_q = rel_q.expand(-1, num_q + num_n, -1, -1)\n#         que_neg_e1, que_neg_e2 = self.split_concat(query, negative)  \n#         p_score, n_score = self.calculate_p_n_score(que_neg_e1, que_neg_e2, rel_q, num_q)\n        \n#         # if not is_eval:\n#         query_y = self.ano_query_forward(ad_maml_clone, task)\n#         p_score = query_y[0] * p_score\n#         n_score = query_y[1:] * n_score\n\n#         return p_score, n_score\n\n\n# device = args.device\n# ad_model = AnomalyDetector(args.ano_k, input_embed_size=args.embed_dim, dropout_p=args.dropout_p)\n# ad_maml = l2l.algorithms.MetaSGD(ad_model, lr=args.adapt_lr)\n# ad_maml.to(device)\n\n# ano_metatl = AnoMetaTL(itemnum, ad_maml, args)\n# ano_metatl.to(device)\n# # if args.metatl_path is not None:\n# #     ano_metatl.load_model(args.metatl_path, args.ad_maml_path)\n# #     print('Used pretrained data')\n# optimizer = optim.Adam([{'params': ano_metatl.embedding.parameters()},\n#                         {'params': ano_metatl.relation_learner.parameters()},\n#                         {'params': ano_metatl.ad_maml.parameters(), 'lr': args.meta_lr}],\n#                         args.metatl_lr)","metadata":{"id":"ZW7f1pJoZFW3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def update_rank(preds, stats):\n#     query_idx = len(preds) - 1\n#     _, idx = torch.sort(preds, descending=True)\n#     idx = idx.cpu().numpy()\n#     rank = np.where(idx == query_idx)[0][0] + 1\n#     # update stats\n#     if rank <= 10:\n#         stats['Hits@10'] += 1\n#         stats['NDCG@10'] += 1 / np.log2(rank + 1)\n#     if rank <= 5:\n#         stats['Hits@5'] += 1\n#         stats['NDCG@5'] += 1 / np.log2(rank + 1)\n#     if rank == 1:\n#         stats['Hits@1'] += 1\n#         stats['NDCG@1'] += 1 / np.log2(rank + 1)\n#     stats['MRR'] += 1.0 / rank\n\n# def eval_model(ano_metatl, eval_dataset):\n#     ano_metatl.eval()\n#     eval_dataset.curr_tri_idx = 0\n#     stats = {'MRR': 0, 'Hits@1': 0, 'Hits@5': 0, 'Hits@10': 0, 'NDCG@1': 0, 'NDCG@5': 0, 'NDCG@10': 0}\n#     eval_batch_size = 0\n\n#     while True:\n#         eval_task, curr_rel = eval_dataset.next_one_on_eval()\n#         if eval_task == 'EOT':\n#             break\n#         eval_batch_size += 1\n#         p_score, n_score = ano_metatl(eval_task, is_eval=True)\n#         preds = torch.cat([n_score, p_score], 1).squeeze()\n#         update_rank(preds, stats)\n\n#     for key in stats.keys():\n#         stats[key] = stats[key] / eval_batch_size\n\n#     print(\"Results: \\tMRR: {:.3f}\\tNDCG@10: {:.3f}\\tNDCG@5: {:.3f}\\tNDCG@1: {:.3f}\\tHits@10: {:.3f}\\tHits@5: {:.3f}\\tHits@1: {:.3f}\\r\".format(\n#             stats['MRR'], stats['NDCG@10'], stats['NDCG@5'], stats['NDCG@1'], stats['Hits@10'], stats['Hits@5'], stats['Hits@1']))","metadata":{"id":"-rEbC7MQz6Qy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for iter in range(args.epoch):\n#     ano_metatl.train()\n#     meta_train_loss = 0\n#     train_task, curr_rel = train_dataset.next_batch()\n#     batch_size = len(train_task[0])\n#     for index in range(batch_size):\n#         task = [[train_task[i][index]] for i in range(len(train_task))]\n#         p_score, n_score = ano_metatl(task)\n#         y = torch.ones_like(p_score).to(device)\n#         meta_train_loss += ano_metatl.loss_func(p_score, n_score, y)\n#     meta_train_loss = meta_train_loss / batch_size\n#     print(f'Iteration: {iter}, Meta Train Loss: {meta_train_loss.item()}')\n\n#     optimizer.zero_grad()\n#     meta_train_loss.backward()\n#     optimizer.step()\n\n#     if iter % args.eval_epoch == 0:\n#         print(f'Validating, Iteration: {iter}')\n#         eval_model(ano_metatl, val_dataset)\n\n#         print(f'Testing, Iteration: {iter}')\n#         eval_model(ano_metatl, test_dataset)","metadata":{"id":"POAHdAhYwmsz","outputId":"02bef188-608f-47e7-d30f-58effc21b373"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.save(ano_metatl.state_dict(), self.metatl_path)\n# torch.save(ad_model.state_dict(), self.ad_maml_path)","metadata":{"id":"J7AClMBxswXM","outputId":"0b9b20bb-e8f0-4403-9ce1-73210132163d"},"execution_count":null,"outputs":[]}]}