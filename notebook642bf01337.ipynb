{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23fa6b8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-09T12:55:08.693297Z",
     "iopub.status.busy": "2023-02-09T12:55:08.692833Z",
     "iopub.status.idle": "2023-02-09T12:55:08.731452Z",
     "shell.execute_reply": "2023-02-09T12:55:08.730567Z"
    },
    "id": "sdUYq0D6TdvE",
    "papermill": {
     "duration": 0.047379,
     "end_time": "2023-02-09T12:55:08.733832",
     "exception": false,
     "start_time": "2023-02-09T12:55:08.686453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9652d908",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-09T12:55:08.742263Z",
     "iopub.status.busy": "2023-02-09T12:55:08.741934Z",
     "iopub.status.idle": "2023-02-09T12:55:58.262807Z",
     "shell.execute_reply": "2023-02-09T12:55:58.261395Z"
    },
    "id": "6npi8bGt2IyS",
    "outputId": "c4d440cc-67bb-4038-aefe-b398763c6288",
    "papermill": {
     "duration": 49.527884,
     "end_time": "2023-02-09T12:55:58.265485",
     "exception": false,
     "start_time": "2023-02-09T12:55:08.737601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting learn2learn\r\n",
      "  Downloading learn2learn-0.1.7.tar.gz (841 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.7/841.7 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /opt/conda/lib/python3.7/site-packages (from learn2learn) (1.21.6)\r\n",
      "Requirement already satisfied: gym>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from learn2learn) (0.26.2)\r\n",
      "Requirement already satisfied: torch>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from learn2learn) (1.11.0)\r\n",
      "Requirement already satisfied: torchvision>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from learn2learn) (0.12.0)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from learn2learn) (1.7.3)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from learn2learn) (2.28.1)\r\n",
      "Collecting gsutil\r\n",
      "  Downloading gsutil-5.20.tar.gz (3.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from learn2learn) (4.64.0)\r\n",
      "Collecting qpth>=0.0.15\r\n",
      "  Downloading qpth-0.0.15.tar.gz (11 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from gym>=0.14.0->learn2learn) (2.1.0)\r\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /opt/conda/lib/python3.7/site-packages (from gym>=0.14.0->learn2learn) (6.0.0)\r\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /opt/conda/lib/python3.7/site-packages (from gym>=0.14.0->learn2learn) (0.0.8)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.1.0->learn2learn) (4.1.1)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.3.0->learn2learn) (9.1.1)\r\n",
      "Collecting argcomplete>=1.9.4\r\n",
      "  Downloading argcomplete-2.0.0-py2.py3-none-any.whl (37 kB)\r\n",
      "Requirement already satisfied: crcmod>=1.7 in /opt/conda/lib/python3.7/site-packages (from gsutil->learn2learn) (1.7)\r\n",
      "Requirement already satisfied: fasteners>=0.14.1 in /opt/conda/lib/python3.7/site-packages (from gsutil->learn2learn) (0.17.3)\r\n",
      "Collecting gcs-oauth2-boto-plugin>=3.0\r\n",
      "  Downloading gcs-oauth2-boto-plugin-3.0.tar.gz (20 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting google-apitools>=0.5.32\r\n",
      "  Downloading google_apitools-0.5.32-py3-none-any.whl (135 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.7/135.7 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: httplib2==0.20.4 in /opt/conda/lib/python3.7/site-packages (from gsutil->learn2learn) (0.20.4)\r\n",
      "Collecting google-reauth>=0.1.0\r\n",
      "  Downloading google_reauth-0.1.1-py2.py3-none-any.whl (17 kB)\r\n",
      "Collecting monotonic>=1.4\r\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\r\n",
      "Requirement already satisfied: pyOpenSSL>=0.13 in /opt/conda/lib/python3.7/site-packages (from gsutil->learn2learn) (22.0.0)\r\n",
      "Collecting retry_decorator>=1.0.0\r\n",
      "  Downloading retry_decorator-1.1.1.tar.gz (3.9 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from gsutil->learn2learn) (1.15.0)\r\n",
      "Collecting google-auth[aiohttp]>=2.5.0\r\n",
      "  Downloading google_auth-2.16.0-py2.py3-none-any.whl (177 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.8/177.8 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.7/site-packages (from httplib2==0.20.4->gsutil->learn2learn) (3.0.9)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->learn2learn) (3.3)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->learn2learn) (1.26.14)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->learn2learn) (2022.12.7)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->learn2learn) (2.1.0)\r\n",
      "Collecting importlib-metadata>=4.8.0\r\n",
      "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\r\n",
      "Collecting rsa==4.7.2\r\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\r\n",
      "Collecting boto>=2.29.1\r\n",
      "  Downloading boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: oauth2client>=2.2.0 in /opt/conda/lib/python3.7/site-packages (from gcs-oauth2-boto-plugin>=3.0->gsutil->learn2learn) (4.1.3)\r\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from rsa==4.7.2->gcs-oauth2-boto-plugin>=3.0->gsutil->learn2learn) (0.4.8)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth[aiohttp]>=2.5.0->gsutil->learn2learn) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth[aiohttp]>=2.5.0->gsutil->learn2learn) (0.2.7)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0dev,>=3.6.2 in /opt/conda/lib/python3.7/site-packages (from google-auth[aiohttp]>=2.5.0->gsutil->learn2learn) (3.8.1)\r\n",
      "Requirement already satisfied: pyu2f in /opt/conda/lib/python3.7/site-packages (from google-reauth>=0.1.0->gsutil->learn2learn) (0.1.5)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.8.0->gym>=0.14.0->learn2learn) (3.8.0)\r\n",
      "Requirement already satisfied: cryptography>=35.0 in /opt/conda/lib/python3.7/site-packages (from pyOpenSSL>=0.13->gsutil->learn2learn) (37.0.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil->learn2learn) (21.4.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil->learn2learn) (1.3.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil->learn2learn) (1.2.0)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil->learn2learn) (4.0.2)\r\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil->learn2learn) (0.13.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil->learn2learn) (6.0.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil->learn2learn) (1.7.2)\r\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.7/site-packages (from cryptography>=35.0->pyOpenSSL>=0.13->gsutil->learn2learn) (1.15.0)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.12->cryptography>=35.0->pyOpenSSL>=0.13->gsutil->learn2learn) (2.21)\r\n",
      "Building wheels for collected packages: learn2learn, qpth, gsutil, gcs-oauth2-boto-plugin, retry_decorator\r\n",
      "  Building wheel for learn2learn (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for learn2learn: filename=learn2learn-0.1.7-cp37-cp37m-linux_x86_64.whl size=1264403 sha256=4390ceaa51858567a095305ba2780f686cd4a188988d0ed7a9322c6d953c1bde\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/66/29/ac/1d46fdb88fb1fb02491123ef3fcec13d5363eb14fec6f8af05\r\n",
      "  Building wheel for qpth (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for qpth: filename=qpth-0.0.15-py3-none-any.whl size=15379 sha256=266a5fc9507fb5d6fd62d784217b78c339c9884b53996d6635b5654dae0243fc\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/f6/bb/0f/3af358159c8cfc56654d85ba5069b53ab351dee72f5a57c2ff\r\n",
      "  Building wheel for gsutil (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for gsutil: filename=gsutil-5.20-py3-none-any.whl size=3784776 sha256=b826e19d37fda8279abe3ed46f9a244ccac6bb7d56606035d0895ca955c8b433\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/3d/70/16/1db14a311a84ddec7c3d3e256ba3b6d4cbdfb34f61512e0490\r\n",
      "  Building wheel for gcs-oauth2-boto-plugin (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for gcs-oauth2-boto-plugin: filename=gcs_oauth2_boto_plugin-3.0-py3-none-any.whl size=23221 sha256=b91d7af38e403f288e12683fbecbc610eafa894b0fdf695e219609c6bc413638\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/2a/93/86/cb2140365b10150dbdba338da385c7c18c7cbd9e592e3421db\r\n",
      "  Building wheel for retry_decorator (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for retry_decorator: filename=retry_decorator-1.1.1-py2.py3-none-any.whl size=3658 sha256=ef62f8b21ff52fe8006ed38e7c7a59670fbcb888add7ab798ab9780afacc13d4\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/91/39/dc/7359c639e34d9c388a1b3e1dc444363905194afc70f57eb9a5\r\n",
      "Successfully built learn2learn qpth gsutil gcs-oauth2-boto-plugin retry_decorator\r\n",
      "Installing collected packages: retry_decorator, monotonic, boto, rsa, qpth, importlib-metadata, google-reauth, google-auth, argcomplete, google-apitools, gcs-oauth2-boto-plugin, gsutil, learn2learn\r\n",
      "  Attempting uninstall: rsa\r\n",
      "    Found existing installation: rsa 4.8\r\n",
      "    Uninstalling rsa-4.8:\r\n",
      "      Successfully uninstalled rsa-4.8\r\n",
      "  Attempting uninstall: importlib-metadata\r\n",
      "    Found existing installation: importlib-metadata 6.0.0\r\n",
      "    Uninstalling importlib-metadata-6.0.0:\r\n",
      "      Successfully uninstalled importlib-metadata-6.0.0\r\n",
      "  Attempting uninstall: google-auth\r\n",
      "    Found existing installation: google-auth 1.35.0\r\n",
      "    Uninstalling google-auth-1.35.0:\r\n",
      "      Successfully uninstalled google-auth-1.35.0\r\n",
      "  Attempting uninstall: google-apitools\r\n",
      "    Found existing installation: google-apitools 0.5.31\r\n",
      "    Uninstalling google-apitools-0.5.31:\r\n",
      "      Successfully uninstalled google-apitools-0.5.31\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "beatrix-jupyterlab 3.1.7 requires google-cloud-bigquery-storage, which is not installed.\r\n",
      "tensorboard 2.6.0 requires google-auth<2,>=1.6.3, but you have google-auth 2.16.0 which is incompatible.\r\n",
      "google-cloud-core 1.7.3 requires google-auth<2.0dev,>=1.24.0, but you have google-auth 2.16.0 which is incompatible.\r\n",
      "google-api-core 1.31.5 requires google-auth<2.0dev,>=1.25.0, but you have google-auth 2.16.0 which is incompatible.\r\n",
      "gcsfs 2022.5.0 requires fsspec==2022.5.0, but you have fsspec 2023.1.0 which is incompatible.\r\n",
      "flake8 5.0.4 requires importlib-metadata<4.3,>=1.1.0; python_version < \"3.8\", but you have importlib-metadata 4.13.0 which is incompatible.\r\n",
      "cmudict 1.0.13 requires importlib-metadata<6.0.0,>=5.1.0, but you have importlib-metadata 4.13.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed argcomplete-2.0.0 boto-2.49.0 gcs-oauth2-boto-plugin-3.0 google-apitools-0.5.32 google-auth-2.16.0 google-reauth-0.1.1 gsutil-5.20 importlib-metadata-4.13.0 learn2learn-0.1.7 monotonic-1.6 qpth-0.0.15 retry_decorator-1.1.1 rsa-4.7.2\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install learn2learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43014e95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-09T12:55:58.284096Z",
     "iopub.status.busy": "2023-02-09T12:55:58.283103Z",
     "iopub.status.idle": "2023-02-09T12:56:01.873250Z",
     "shell.execute_reply": "2023-02-09T12:56:01.871896Z"
    },
    "id": "6qYS9wSEsEwr",
    "outputId": "5ce3a9e2-d089-4eaa-c631-34eb77890511",
    "papermill": {
     "duration": 3.602165,
     "end_time": "2023-02-09T12:56:01.876070",
     "exception": false,
     "start_time": "2023-02-09T12:55:58.273905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of google.oauth2.service_account failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/opt/conda/lib/python3.7/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/opt/conda/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/google/oauth2/service_account.py\", line 90, in <module>\n",
      "    credentials.CredentialsWithTokenUri,\n",
      "AttributeError: module 'google.auth.credentials' has no attribute 'CredentialsWithTokenUri'\n",
      "]\n",
      "[autoreload of google.auth.jwt failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/opt/conda/lib/python3.7/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/opt/conda/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/google/auth/jwt.py\", line 327, in <module>\n",
      "    google.auth.credentials.Signing, google.auth.credentials.CredentialsWithQuotaProject\n",
      "AttributeError: module 'google.auth' has no attribute 'credentials'\n",
      "]\n",
      "[autoreload of importlib_metadata failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 410, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 302, in update_class\n",
      "    if update_generic(old_obj, new_obj): continue\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 266, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: __getitem__() requires a code object with 0 free vars, not 1\n",
      "]\n",
      "[autoreload of importlib_metadata._adapters failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 410, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 302, in update_class\n",
      "    if update_generic(old_obj, new_obj): continue\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 266, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: __getitem__() requires a code object with 1 free vars, not 0\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Ano-MetaTL'...\r\n",
      "remote: Enumerating objects: 51, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (51/51), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (39/39), done.\u001b[K\r\n",
      "remote: Total 51 (delta 18), reused 37 (delta 10), pack-reused 0\u001b[K\r\n",
      "Unpacking objects: 100% (51/51), 2.43 MiB | 7.66 MiB/s, done.\r\n",
      "/kaggle/working/Ano-MetaTL\n",
      "Note: switching to 'origin/ad_maml'.\r\n",
      "\r\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\r\n",
      "changes and commit them, and you can discard any commits you make in this\r\n",
      "state without impacting any branches by switching back to a branch.\r\n",
      "\r\n",
      "If you want to create a new branch to retain commits you create, you may\r\n",
      "do so (now or later) by using -c with the switch command. Example:\r\n",
      "\r\n",
      "  git switch -c <new-branch-name>\r\n",
      "\r\n",
      "Or undo this operation with:\r\n",
      "\r\n",
      "  git switch -\r\n",
      "\r\n",
      "Turn off this advice by setting config variable advice.detachedHead to false\r\n",
      "\r\n",
      "HEAD is now at 70e3c29 Kaggle Notebook | notebook642bf01337 | Version 7\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/parnianrazavipour/Ano-MetaTL.git\n",
    "%cd Ano-MetaTL\n",
    "!git checkout origin/ad_maml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2abe2c5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-09T12:56:01.898471Z",
     "iopub.status.busy": "2023-02-09T12:56:01.897406Z",
     "iopub.status.idle": "2023-02-09T12:56:01.931570Z",
     "shell.execute_reply": "2023-02-09T12:56:01.930695Z"
    },
    "id": "YZItj6PHrlhZ",
    "outputId": "28754d31-6af6-4650-fbc4-9f995a1c7ea5",
    "papermill": {
     "duration": 0.047232,
     "end_time": "2023-02-09T12:56:01.933683",
     "exception": false,
     "start_time": "2023-02-09T12:56:01.886451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4444d49b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-09T12:56:01.952658Z",
     "iopub.status.busy": "2023-02-09T12:56:01.952373Z",
     "iopub.status.idle": "2023-02-09T12:56:01.982505Z",
     "shell.execute_reply": "2023-02-09T12:56:01.981605Z"
    },
    "id": "c4DVKQ4BryGG",
    "outputId": "f8a55134-21ae-4ee7-ea45-bbc5d195e054",
    "papermill": {
     "duration": 0.042205,
     "end_time": "2023-02-09T12:56:01.984795",
     "exception": false,
     "start_time": "2023-02-09T12:56:01.942590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# path = \"../drive/MyDrive/Rabiee/Social/metatl_beauty/models\"\n",
    "# os.system(f'cp -r {path} .')\n",
    "# path = \"../drive/MyDrive/Rabiee/Social/data/\"\n",
    "# os.system(f'cp -r {path} .')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a5eaa7",
   "metadata": {
    "papermill": {
     "duration": 0.008816,
     "end_time": "2023-02-09T12:56:02.002709",
     "exception": false,
     "start_time": "2023-02-09T12:56:01.993893",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ee60749",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-09T12:56:02.023096Z",
     "iopub.status.busy": "2023-02-09T12:56:02.022414Z",
     "iopub.status.idle": "2023-02-09T12:56:11.330935Z",
     "shell.execute_reply": "2023-02-09T12:56:11.329899Z"
    },
    "id": "nArZhXjA7dkD",
    "papermill": {
     "duration": 9.321683,
     "end_time": "2023-02-09T12:56:11.333709",
     "exception": false,
     "start_time": "2023-02-09T12:56:02.012026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "k = 5\n",
    "min_intrac = k+1 \n",
    "#set w.r.t k\n",
    "train_test_p = 0.7\n",
    "\n",
    "ratings = pd.read_csv(\"/kaggle/input/ratings-beauty/ratings_Beauty.csv\",\n",
    "                      names=['user_id', 'product_id','rating','timestamp'])\n",
    "\n",
    "ratings = ratings[ratings.groupby('user_id')['user_id'].transform('count').ge(min_intrac)]\n",
    "\n",
    "start_df = ratings.groupby(['user_id'])['timestamp'].agg('min')\n",
    "ratings['start_ts'] = ratings['user_id'].apply(lambda x: start_df[x])\n",
    "ratings = ratings.sort_values(['start_ts', 'user_id', 'timestamp'], ascending=[True, True, True])\n",
    "\n",
    "all_user, idx = np.unique(ratings['user_id'], return_index=True)\n",
    "user_dic = {}\n",
    "all_user = all_user[np.argsort(idx)]\n",
    "for i, user in enumerate(all_user):\n",
    "    user_dic[user] = i + 1\n",
    "ratings['user_id'] =  ratings['user_id'].apply(lambda user: user_dic[user])\n",
    "\n",
    "all_item, item_idx = np.unique(ratings['product_id'], return_index=True)\n",
    "item_dic = {}\n",
    "all_item = all_item[np.argsort(item_idx)]\n",
    "for i, item in enumerate(all_item):\n",
    "    item_dic[item] = i + 1\n",
    "ratings['product_id'] =  ratings['product_id'].apply(lambda item: item_dic[item])\n",
    "\n",
    "ratings = ratings.reset_index(drop=True)\n",
    "ratings = ratings.drop(['rating', 'start_ts'], axis=1)\n",
    "\n",
    "sep_user = max(ratings.user_id) * (train_test_p)\n",
    "train_df = ratings[ratings['user_id'] <= sep_user]\n",
    "test_df = ratings[ratings['user_id'] > sep_user]\n",
    "test_df = test_df[test_df.product_id <= max(train_df.product_id)]\n",
    "\n",
    "if not os.path.exists('./data'):\n",
    "    os.mkdir('./data')\n",
    "if not os.path.exists('./data/beauty'):\n",
    "    os.mkdir('./data/beauty')\n",
    "    \n",
    "train_df.to_csv('data/beauty/beauty_train.csv', sep='\\t', header=False, index=False)\n",
    "test_df.to_csv('data/beauty/beauty_test_new_user.csv', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e838277f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-09T12:56:11.353263Z",
     "iopub.status.busy": "2023-02-09T12:56:11.352930Z",
     "iopub.status.idle": "2023-02-09T12:56:11.389362Z",
     "shell.execute_reply": "2023-02-09T12:56:11.388211Z"
    },
    "papermill": {
     "duration": 0.048355,
     "end_time": "2023-02-09T12:56:11.391885",
     "exception": false,
     "start_time": "2023-02-09T12:56:11.343530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'Ano-MetaTL'\n",
      "/kaggle/working/Ano-MetaTL\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/Ano-MetaTL'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd Ano-MetaTL\n",
    "%pwd\n",
    "# !conda install pytorch --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9c768e",
   "metadata": {
    "papermill": {
     "duration": 0.008761,
     "end_time": "2023-02-09T12:56:11.409869",
     "exception": false,
     "start_time": "2023-02-09T12:56:11.401108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eb8ec77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-09T12:56:11.428943Z",
     "iopub.status.busy": "2023-02-09T12:56:11.428085Z",
     "iopub.status.idle": "2023-02-09T12:56:12.980565Z",
     "shell.execute_reply": "2023-02-09T12:56:12.979509Z"
    },
    "id": "1ybwiY8U1hSC",
    "papermill": {
     "duration": 1.564558,
     "end_time": "2023-02-09T12:56:12.983159",
     "exception": false,
     "start_time": "2023-02-09T12:56:11.418601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch, random\n",
    "import os \n",
    "\n",
    "class Arguments:\n",
    "    def __init__(self):\n",
    "        self.dataset = \"beauty\"\n",
    "        self.seed = 0\n",
    "        self.K = 5\n",
    "        self.embed_dim = 100\n",
    "        self.batch_size = 1024\n",
    "        self.learning_rate = 0.001\n",
    "        self.epoch = 20000\n",
    "        self.print_epoch = 100\n",
    "        self.eval_epoch = 500\n",
    "        self.beta = 5\n",
    "        self.margin = 1\n",
    "        self.dropout_p = 0.5\n",
    "        self.device = 0\n",
    "        self.ano_k = self.K\n",
    "        self.adapt_lr = 0.01\n",
    "        self.meta_lr = 0.005\n",
    "        self.metatl_path = 'models/metatl.pt'\n",
    "        self.ad_maml_path = 'models/maml_ad.pt'\n",
    "\n",
    "args = Arguments()\n",
    "args.device = torch.device('cuda:'+str(args.device))\n",
    "params = {}\n",
    "for attr, value in args.__dict__.items():\n",
    "    params[attr] = value\n",
    "# params['device'] = torch.device('cuda:'+str(args.device))\n",
    "# args.device = 'cpu'\n",
    "# params['device'] = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76136bc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-09T12:56:13.003591Z",
     "iopub.status.busy": "2023-02-09T12:56:13.003035Z",
     "iopub.status.idle": "2023-02-09T14:00:16.055437Z",
     "shell.execute_reply": "2023-02-09T14:00:16.054228Z"
    },
    "id": "QqnBedVW_k_H",
    "outputId": "f0752044-463c-4edb-996f-e25420bd6df1",
    "papermill": {
     "duration": 3843.065534,
     "end_time": "2023-02-09T14:00:16.058347",
     "exception": false,
     "start_time": "2023-02-09T12:56:12.992813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19600\tLoss: 0.0202Epoch: 19700\tLoss: 0.0160Epoch: 19800\tLoss: 0.0219Epoch: 19900\tLoss: 0.0250Finish\n"
     ]
    }
   ],
   "source": [
    "from trainer import *\n",
    "from utils import *\n",
    "from sampler import *\n",
    "import json\n",
    "\n",
    "\n",
    "if params['seed'] is not None:\n",
    "    SEED = params['seed']\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "user_train, usernum_train, itemnum, user_input_test, user_test, user_input_valid, user_valid = data_load(args.dataset, args.K)    \n",
    "\n",
    "train_dataset = WarpSampler(user_train, usernum_train, itemnum, sample_function_mixed, batch_size=args.batch_size, maxlen=args.K, n_workers=3)\n",
    "\n",
    "test_dataset = DataLoader(user_input_test, user_test, itemnum, params)\n",
    "\n",
    "val_dataset = DataLoader(user_input_valid, user_valid, itemnum, params)\n",
    "\n",
    "\n",
    "user_train, usernum_train, itemnum, user_input_test, user_test, user_input_valid, user_valid = data_load(args.dataset, args.K)    \n",
    "\n",
    "trainer = Trainer([train_dataset, val_dataset ,test_dataset], itemnum, params)\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad61577a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-09T14:00:16.131948Z",
     "iopub.status.busy": "2023-02-09T14:00:16.131399Z",
     "iopub.status.idle": "2023-02-09T14:00:16.193116Z",
     "shell.execute_reply": "2023-02-09T14:00:16.192250Z"
    },
    "id": "uaOKyOisHHmA",
    "outputId": "e2ddd8df-af98-45d4-cd87-77356cf419cf",
    "papermill": {
     "duration": 0.099704,
     "end_time": "2023-02-09T14:00:16.195591",
     "exception": false,
     "start_time": "2023-02-09T14:00:16.095887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/Ano-MetaTL'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2b35bb",
   "metadata": {
    "id": "QFNsZET96LVG",
    "papermill": {
     "duration": 0.040122,
     "end_time": "2023-02-09T14:00:16.299406",
     "exception": false,
     "start_time": "2023-02-09T14:00:16.259284",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea1f277e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-09T14:00:16.368030Z",
     "iopub.status.busy": "2023-02-09T14:00:16.367636Z",
     "iopub.status.idle": "2023-02-09T14:00:16.419179Z",
     "shell.execute_reply": "2023-02-09T14:00:16.418368Z"
    },
    "id": "ZW7f1pJoZFW3",
    "papermill": {
     "duration": 0.088669,
     "end_time": "2023-02-09T14:00:16.421574",
     "exception": false,
     "start_time": "2023-02-09T14:00:16.332905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from torch import nn\n",
    "# from models import Embedding, MetaLearner\n",
    "# from ad_maml.model import AnomalyDetector\n",
    "# from torch.autograd import grad\n",
    "# from torch import optim\n",
    "# import learn2learn as l2l\n",
    "# from collections import OrderedDict\n",
    "\n",
    "\n",
    "# class AnoMetaTL(nn.Module):\n",
    "#     def __init__(self, max_item, ad_maml, args):\n",
    "#         super(AnoMetaTL, self).__init__()\n",
    "#         self.device = args.device\n",
    "#         self.beta = args.beta\n",
    "#         self.embedding = nn.Embedding(max_item + 1, args.embed_dim)\n",
    "#         nn.init.xavier_uniform_(self.embedding.weight)\n",
    "#         self.relation_learner = MetaLearner(args.K - 1, embed_size=args.embed_dim, num_hidden1=500,\n",
    "#                                                     num_hidden2=200, out_size=100, dropout_p=args.dropout_p)\n",
    "#         self.loss_func = nn.MarginRankingLoss(args.margin)\n",
    "#         self.ad_maml = ad_maml\n",
    "\n",
    "#     def split_concat(self, positive, negative):\n",
    "#         pos_neg_e1 = torch.cat([positive[:, :, 0, :],\n",
    "#                                 negative[:, :, 0, :]], 1).unsqueeze(2)\n",
    "#         pos_neg_e2 = torch.cat([positive[:, :, 1, :],\n",
    "#                                 negative[:, :, 1, :]], 1).unsqueeze(2)\n",
    "#         return pos_neg_e1, pos_neg_e2\n",
    "\n",
    "#     def embedding_triples(self, triples):\n",
    "#         idx = [[[t[0], t[2]] for t in batch] for batch in triples]\n",
    "#         idx = torch.LongTensor(idx).to(self.device)\n",
    "#         return self.embedding(idx)\n",
    "\n",
    "#     def calculate_p_n_score(self, start, target, transition, k):\n",
    "#         score = -torch.norm(start + transition - target, 2, -1).squeeze(2)\n",
    "#         p_score = score[:, :k]\n",
    "#         n_score = score[:, k:]\n",
    "#         return p_score, n_score\n",
    "    \n",
    "#     def get_ano_support_task(self, task):\n",
    "#         support_triples, support_negative_triples, \\\n",
    "#             query_triples, negative_triples, = [item[0] for item in task]\n",
    "#         support = [*np.array(support_triples)[:, 0], np.array(support_triples)[-1, -1]]\n",
    "#         support_neg = [*np.array(support_negative_triples)[:, 2]]\n",
    "#         return support, support_neg\n",
    "\n",
    "#     def get_ano_query_task(self, task):\n",
    "#         support_triples, support_negative_triples, \\\n",
    "#             query_triples, negative_triples, = [item[0] for item in task]\n",
    "#         support = [*np.array(support_triples)[:, 0], np.array(support_triples)[-1, -1]]\n",
    "#         query = []\n",
    "#         query.append([*support[-self.ad_maml.k + 1:], query_triples[0][2]])\n",
    "#         for neg_triple in negative_triples:\n",
    "#             query.append([*support[-self.ad_maml.k + 1:], neg_triple[2]])\n",
    "#         return query\n",
    "\n",
    "#     def get_ano_preds(self, ad_maml_clone, data):\n",
    "#         data_embed = self.embedding(data)\n",
    "#         data_ano = data_embed[-1].unsqueeze(0)\n",
    "#         data_embed = data_embed.reshape(-1).unsqueeze(0)\n",
    "#         preds = ad_maml_clone(data_embed, data_ano)\n",
    "#         return preds.squeeze(0)\n",
    "\n",
    "#     def ano_support_forward(self, ad_maml_clone, task):\n",
    "#         ano_k = ad_maml_clone.k\n",
    "#         support_y = []\n",
    "#         support_neg_y = []\n",
    "#         all_support, all_support_neg = self.get_ano_support_task(task)\n",
    "#         for i, neg in enumerate(all_support_neg[:ano_k - 2]):\n",
    "#             support = all_support[:ano_k]\n",
    "#             support[-1], support[i + 1] = support[i + 1], support[-1]\n",
    "#             support = torch.tensor(support).to(self.device)\n",
    "#             support_y.append(self.get_ano_preds(ad_maml_clone, support))\n",
    "#             support_neg = [*support[:-1], neg]\n",
    "#             support_neg = torch.tensor(support_neg).to(self.device)\n",
    "#             support_neg_y.append(self.get_ano_preds(ad_maml_clone, support_neg))\n",
    "#         for i, neg in enumerate(all_support_neg[ano_k - 2:]):\n",
    "#             support = all_support[i: i + ano_k]\n",
    "#             support = torch.tensor(support).to(self.device)\n",
    "#             support_y.append(self.get_ano_preds(ad_maml_clone, support))\n",
    "#             support_neg = [*support[:-1], neg]\n",
    "#             support_neg = torch.tensor(support_neg).to(self.device)\n",
    "#             support_neg_y.append(self.get_ano_preds(ad_maml_clone, support_neg))\n",
    "#         support_y = torch.cat(support_y)\n",
    "#         support_neg_y = torch.cat(support_neg_y)\n",
    "#         return support_y, support_neg_y\n",
    "\n",
    "#     def ano_query_forward(self, ad_maml_clone, task):\n",
    "#         query_y = []\n",
    "#         all_query = self.get_ano_query_task(task)\n",
    "#         all_query = torch.tensor(all_query).to(self.device)\n",
    "#         data_embed = self.embedding(all_query)\n",
    "#         data_ano = data_embed[:, -1, :]\n",
    "#         data_embed = data_embed.reshape(data_embed.shape[0], -1)\n",
    "#         preds = ad_maml_clone(data_embed, data_ano)\n",
    "#         return preds.reshape(-1)\n",
    "\n",
    "#     # def load_model(self, metatl_path, ad_maml_path):\n",
    "#     #     #load embedder\n",
    "#     #     metatl_data = torch.load(metatl_path, map_location=torch.device(self.device))\n",
    "#     #     self.embedding.load_state_dict(OrderedDict([('weight', metatl_data['embedding.embedding.weight'])]))\n",
    "#     #     #load relation learner\n",
    "#     #     rl_name = 'relation_learner'\n",
    "#     #     all_keys = []\n",
    "#     #     for key in metatl_data.keys():\n",
    "#     #         if  rl_name in key:\n",
    "#     #             all_keys.append(key)\n",
    "\n",
    "#     #     rl_data = []\n",
    "#     #     for key in all_keys:\n",
    "#     #         rl_data.append((key[len(rl_name) + 1:], metatl_data[key]))\n",
    "#     #     self.relation_learner.load_state_dict(OrderedDict(rl_data))\n",
    "#     #     #load ad_maml\n",
    "#     #     ad_maml_data = torch.load(ad_maml_path, map_location=torch.device(self.device))\n",
    "#     #     self.ad_maml.load_state_dict(ad_maml_data)\n",
    "\n",
    "#     def forward(self, task, is_eval=False):\n",
    "#         # transfer task string into embedding\n",
    "#         support, support_negative, query, negative = [self.embedding_triples(t) for t in task]\n",
    " \n",
    "#         K = support.shape[1]              # num of K\n",
    "#         num_sn = support_negative.shape[1]  # num of support negative\n",
    "#         num_q = query.shape[1]              # num of query\n",
    "#         num_n = negative.shape[1]           # num of query negative\n",
    "\n",
    "#         rel = self.relation_learner(support)\n",
    "#         rel.retain_grad()\n",
    "#         rel_s = rel.expand(-1, K+num_sn, -1, -1)\n",
    "\n",
    "#         sup_neg_e1, sup_neg_e2 = self.split_concat(support, support_negative)\n",
    "#         p_score, n_score = self.calculate_p_n_score(sup_neg_e1, sup_neg_e2, rel_s, K)\n",
    "#         ad_maml_clone = self.ad_maml.clone()\n",
    "#         support_y, support_neg_y = self.ano_support_forward(ad_maml_clone, task)\n",
    "#         p_score = support_y * p_score\n",
    "#         n_score = support_neg_y * n_score\n",
    "\n",
    "#         y = torch.ones_like(p_score).to(self.device)\n",
    "#         support_loss = self.loss_func(p_score, n_score, y)\n",
    "#         ad_maml_clone.adapt(support_loss)\n",
    "#         rel_q = rel - self.beta * grad(support_loss, rel, retain_graph=True)[0]\n",
    "        \n",
    "#         rel_q = rel_q.expand(-1, num_q + num_n, -1, -1)\n",
    "#         que_neg_e1, que_neg_e2 = self.split_concat(query, negative)  \n",
    "#         p_score, n_score = self.calculate_p_n_score(que_neg_e1, que_neg_e2, rel_q, num_q)\n",
    "        \n",
    "#         # if not is_eval:\n",
    "#         query_y = self.ano_query_forward(ad_maml_clone, task)\n",
    "#         p_score = query_y[0] * p_score\n",
    "#         n_score = query_y[1:] * n_score\n",
    "\n",
    "#         return p_score, n_score\n",
    "\n",
    "\n",
    "# device = args.device\n",
    "# ad_model = AnomalyDetector(args.ano_k, input_embed_size=args.embed_dim, dropout_p=args.dropout_p)\n",
    "# ad_maml = l2l.algorithms.MetaSGD(ad_model, lr=args.adapt_lr)\n",
    "# ad_maml.to(device)\n",
    "\n",
    "# ano_metatl = AnoMetaTL(itemnum, ad_maml, args)\n",
    "# ano_metatl.to(device)\n",
    "# # if args.metatl_path is not None:\n",
    "# #     ano_metatl.load_model(args.metatl_path, args.ad_maml_path)\n",
    "# #     print('Used pretrained data')\n",
    "# optimizer = optim.Adam([{'params': ano_metatl.embedding.parameters()},\n",
    "#                         {'params': ano_metatl.relation_learner.parameters()},\n",
    "#                         {'params': ano_metatl.ad_maml.parameters(), 'lr': args.meta_lr}],\n",
    "#                         args.metatl_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e813ead4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-09T14:00:16.488656Z",
     "iopub.status.busy": "2023-02-09T14:00:16.488337Z",
     "iopub.status.idle": "2023-02-09T14:00:16.536243Z",
     "shell.execute_reply": "2023-02-09T14:00:16.535623Z"
    },
    "id": "-rEbC7MQz6Qy",
    "papermill": {
     "duration": 0.083095,
     "end_time": "2023-02-09T14:00:16.538032",
     "exception": false,
     "start_time": "2023-02-09T14:00:16.454937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def update_rank(preds, stats):\n",
    "#     query_idx = len(preds) - 1\n",
    "#     _, idx = torch.sort(preds, descending=True)\n",
    "#     idx = idx.cpu().numpy()\n",
    "#     rank = np.where(idx == query_idx)[0][0] + 1\n",
    "#     # update stats\n",
    "#     if rank <= 10:\n",
    "#         stats['Hits@10'] += 1\n",
    "#         stats['NDCG@10'] += 1 / np.log2(rank + 1)\n",
    "#     if rank <= 5:\n",
    "#         stats['Hits@5'] += 1\n",
    "#         stats['NDCG@5'] += 1 / np.log2(rank + 1)\n",
    "#     if rank == 1:\n",
    "#         stats['Hits@1'] += 1\n",
    "#         stats['NDCG@1'] += 1 / np.log2(rank + 1)\n",
    "#     stats['MRR'] += 1.0 / rank\n",
    "\n",
    "# def eval_model(ano_metatl, eval_dataset):\n",
    "#     ano_metatl.eval()\n",
    "#     eval_dataset.curr_tri_idx = 0\n",
    "#     stats = {'MRR': 0, 'Hits@1': 0, 'Hits@5': 0, 'Hits@10': 0, 'NDCG@1': 0, 'NDCG@5': 0, 'NDCG@10': 0}\n",
    "#     eval_batch_size = 0\n",
    "\n",
    "#     while True:\n",
    "#         eval_task, curr_rel = eval_dataset.next_one_on_eval()\n",
    "#         if eval_task == 'EOT':\n",
    "#             break\n",
    "#         eval_batch_size += 1\n",
    "#         p_score, n_score = ano_metatl(eval_task, is_eval=True)\n",
    "#         preds = torch.cat([n_score, p_score], 1).squeeze()\n",
    "#         update_rank(preds, stats)\n",
    "\n",
    "#     for key in stats.keys():\n",
    "#         stats[key] = stats[key] / eval_batch_size\n",
    "\n",
    "#     print(\"Results: \\tMRR: {:.3f}\\tNDCG@10: {:.3f}\\tNDCG@5: {:.3f}\\tNDCG@1: {:.3f}\\tHits@10: {:.3f}\\tHits@5: {:.3f}\\tHits@1: {:.3f}\\r\".format(\n",
    "#             stats['MRR'], stats['NDCG@10'], stats['NDCG@5'], stats['NDCG@1'], stats['Hits@10'], stats['Hits@5'], stats['Hits@1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78b2371e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-09T14:00:16.589988Z",
     "iopub.status.busy": "2023-02-09T14:00:16.589697Z",
     "iopub.status.idle": "2023-02-09T14:00:16.620830Z",
     "shell.execute_reply": "2023-02-09T14:00:16.620002Z"
    },
    "id": "POAHdAhYwmsz",
    "outputId": "02bef188-608f-47e7-d30f-58effc21b373",
    "papermill": {
     "duration": 0.056159,
     "end_time": "2023-02-09T14:00:16.622907",
     "exception": false,
     "start_time": "2023-02-09T14:00:16.566748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for iter in range(args.epoch):\n",
    "#     ano_metatl.train()\n",
    "#     meta_train_loss = 0\n",
    "#     train_task, curr_rel = train_dataset.next_batch()\n",
    "#     batch_size = len(train_task[0])\n",
    "#     for index in range(batch_size):\n",
    "#         task = [[train_task[i][index]] for i in range(len(train_task))]\n",
    "#         p_score, n_score = ano_metatl(task)\n",
    "#         y = torch.ones_like(p_score).to(device)\n",
    "#         meta_train_loss += ano_metatl.loss_func(p_score, n_score, y)\n",
    "#     meta_train_loss = meta_train_loss / batch_size\n",
    "#     print(f'Iteration: {iter}, Meta Train Loss: {meta_train_loss.item()}')\n",
    "\n",
    "#     optimizer.zero_grad()\n",
    "#     meta_train_loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     if iter % args.eval_epoch == 0:\n",
    "#         print(f'Validating, Iteration: {iter}')\n",
    "#         eval_model(ano_metatl, val_dataset)\n",
    "\n",
    "#         print(f'Testing, Iteration: {iter}')\n",
    "#         eval_model(ano_metatl, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0202737",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-09T14:00:16.669012Z",
     "iopub.status.busy": "2023-02-09T14:00:16.668719Z",
     "iopub.status.idle": "2023-02-09T14:00:16.699679Z",
     "shell.execute_reply": "2023-02-09T14:00:16.698739Z"
    },
    "id": "J7AClMBxswXM",
    "outputId": "0b9b20bb-e8f0-4403-9ce1-73210132163d",
    "papermill": {
     "duration": 0.056814,
     "end_time": "2023-02-09T14:00:16.702105",
     "exception": false,
     "start_time": "2023-02-09T14:00:16.645291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.save(ano_metatl.state_dict(), self.metatl_path)\n",
    "# torch.save(ad_model.state_dict(), self.ad_maml_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3918.534295,
   "end_time": "2023-02-09T14:00:19.552512",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-09T12:55:01.018217",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
